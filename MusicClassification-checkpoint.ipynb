{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe31c6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:180: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import numpy as np\n",
    "import librosa\n",
    "import joblib\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Load pre-trained Decision Tree model and scaler\n",
    "classifier = joblib.load('decision_tree_classifier.pkl')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "label_encoder = joblib.load('label_encoder.pkl')\n",
    "\n",
    "# Fungsi ekstraksi fitur (dari kode yang Anda berikan)\n",
    "def extract_rhythm_features(y, sr):\n",
    "    tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
    "    onset_env = librosa.onset.onset_strength(y=y, sr=sr)\n",
    "    return tempo, np.mean(onset_env), np.std(onset_env)\n",
    "\n",
    "def extract_frequency_features(y, sr, n_mfcc=20):\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    return (\n",
    "        np.mean(mfcc.T, axis=0),\n",
    "        np.mean(chroma.T, axis=0),\n",
    "        np.mean(spectral_contrast.T, axis=0),\n",
    "        np.mean(spectral_centroid.T, axis=0)\n",
    "    )\n",
    "\n",
    "def extract_f0_features(y, sr, f0_min=50, f0_max=400):\n",
    "    pitches, magnitudes = librosa.core.piptrack(y=y, sr=sr, fmin=f0_min, fmax=f0_max, threshold=0.75)\n",
    "    f0_values = [pitches[magnitudes[:, i].argmax(), i] for i in range(magnitudes.shape[1]) if magnitudes[:, i].any()]\n",
    "    if f0_values:\n",
    "        f0_mean = np.mean(f0_values)\n",
    "        f0_std = np.std(f0_values)\n",
    "    else:\n",
    "        f0_mean = 0\n",
    "        f0_std = 0\n",
    "    return f0_mean, f0_std\n",
    "\n",
    "def extract_features(y, sr, num_segments=5, n_mfcc=20, n_fft=2048, hop_length=512):\n",
    "    num_samples_per_segment = int(len(y) / num_segments)\n",
    "    all_features = []\n",
    "    \n",
    "    for s in range(num_segments):\n",
    "        start_sample = s * num_samples_per_segment\n",
    "        end_sample = start_sample + num_samples_per_segment\n",
    "        segment = y[start_sample:end_sample]\n",
    "        \n",
    "        mfcc_mean, chroma_mean, spectral_contrast_mean, spectral_centroid_mean = extract_frequency_features(segment, sr, n_mfcc)\n",
    "        tempo, onset_env_mean, onset_env_std = extract_rhythm_features(segment, sr)\n",
    "        f0_mean, f0_std = extract_f0_features(segment, sr)\n",
    "        \n",
    "        features = np.concatenate([\n",
    "            mfcc_mean, chroma_mean, spectral_contrast_mean, spectral_centroid_mean, \n",
    "            [tempo, onset_env_mean, onset_env_std, f0_mean, f0_std]\n",
    "        ])\n",
    "        all_features.append(features)\n",
    "    \n",
    "    all_features_mean = np.mean(all_features, axis=0)\n",
    "    return all_features_mean\n",
    "\n",
    "# Initialize main window\n",
    "root = tk.Tk()\n",
    "root.title(\"Music Genre Classification\")\n",
    "\n",
    "def play_song():\n",
    "    song_path = song_listbox.get(tk.ACTIVE)\n",
    "    if song_path:\n",
    "        song = AudioSegment.from_file(song_path)\n",
    "        play(song)\n",
    "\n",
    "def predict_genre_from_file():\n",
    "    song_path = song_listbox.get(tk.ACTIVE)\n",
    "    if song_path:\n",
    "        y, sr = librosa.load(song_path)\n",
    "        features = extract_features(y, sr)\n",
    "        features = scaler.transform([features])\n",
    "        genre_index = classifier.predict(features)\n",
    "        genre = label_encoder.inverse_transform(genre_index)[0]\n",
    "        genre_output_box.delete(\"1.0\", tk.END)\n",
    "        genre_output_box.insert(tk.END, f\"Predicted Genre: {genre}\")\n",
    "\n",
    "def record_audio():\n",
    "    duration = 10\n",
    "    fs = 44100\n",
    "    messagebox.showinfo(\"Recording\", \"Recording for 30 seconds...\")\n",
    "    recording = sd.rec(int(duration * fs), samplerate=fs, channels=2)\n",
    "    sd.wait()\n",
    "    sf.write(\"recorded_audio.wav\", recording, fs)\n",
    "    predict_genre_from_recording(\"recorded_audio.wav\")\n",
    "\n",
    "def predict_genre_from_recording(file_path):\n",
    "    y, sr = librosa.load(file_path)\n",
    "    features = extract_features(y, sr)\n",
    "    features = scaler.transform([features])\n",
    "    genre_index = classifier.predict(features)\n",
    "    genre = label_encoder.inverse_transform(genre_index)[0]\n",
    "    genre_output_box.delete(\"1.0\", tk.END)\n",
    "    genre_output_box.insert(tk.END, f\"Predicted Genre: {genre}\")\n",
    "\n",
    "frame = tk.Frame(root)\n",
    "frame.pack(pady=20)\n",
    "\n",
    "song_listbox = tk.Listbox(frame, width=50, height=10)\n",
    "song_listbox.pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "scrollbar = tk.Scrollbar(frame, orient=\"vertical\")\n",
    "scrollbar.config(command=song_listbox.yview)\n",
    "scrollbar.pack(side=tk.LEFT, fill=\"y\")\n",
    "\n",
    "song_listbox.config(yscrollcommand=scrollbar.set)\n",
    "\n",
    "def load_dataset_songs():\n",
    "    file_paths = filedialog.askopenfilenames(filetypes=[(\"Audio Files\", \"*.wav\")])\n",
    "    if file_paths:\n",
    "        for file_path in file_paths:\n",
    "            song_listbox.insert(tk.END, file_path)\n",
    "\n",
    "load_dataset_button = tk.Button(root, text=\"Load Dataset Songs\", command=load_dataset_songs)\n",
    "load_dataset_button.pack(pady=10)\n",
    "\n",
    "play_button = tk.Button(root, text=\"Play Song\", command=play_song)\n",
    "play_button.pack(pady=10)\n",
    "\n",
    "predict_button = tk.Button(root, text=\"Predict Genre from File\", command=predict_genre_from_file)\n",
    "predict_button.pack(pady=10)\n",
    "\n",
    "record_button = tk.Button(root, text=\"Record and Predict Genre\", command=record_audio)\n",
    "record_button.pack(pady=10)\n",
    "\n",
    "genre_output_box = tk.Text(root, height=2, width=50)\n",
    "genre_output_box.pack(pady=10)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84a4d68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
